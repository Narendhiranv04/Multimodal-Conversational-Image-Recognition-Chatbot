Multimodal Conversational Image Recognition Chatbot

This project was developed as part of Smart India Hackathon-24, showcasing a multimodal chatbot capable of handling complex image-based queries. The chatbot integrates cutting-edge technologies to provide image segmentation, inpainting, and generation capabilities, combined with conversational intelligence to ensure a seamless and engaging user experience.

The system utilizes LLaVA, SAM2, and GLIGEN to process images for segmentation, inpainting, and generation tasks, while LSTM networks enhance the chatbot’s contextual understanding. Advanced keyword extraction techniques using RAKE and YAKE further refine conversational responses, making the chatbot reliable and accurate in addressing user queries.
Features

1. Multimodal interaction combining text and image understanding.
2. Image segmentation, inpainting, and generation using state-of-the-art models.
3. Context-aware conversation using LSTM-based memory management.
4. Keyword extraction with RAKE and YAKE for enhanced response accuracy.
5. Designed to handle complex queries, delivering precise and engaging responses.

Technologies Used

LLaVA: A Large Language and Vision Assistant for multimodal understanding.
    
SAM2: A powerful image segmentation model.
    
GLIGEN: Framework for image inpainting and generation.    

RAKE and YAKE: Tools for keyword extraction to enhance chatbot performance.
    
LSTM Networks: Used for managing contextual memory in conversations.

How It Works
    
Image Processing: The chatbot processes uploaded images or image links for segmentation, inpainting, and generation tasks using SAM2 and GLIGEN.

Conversational Interaction: LLaVA interprets user queries related to the image and provides relevant responses.

Keyword Extraction: RAKE and YAKE extract key phrases to refine the chatbot’s understanding and enhance the relevance of its replies.

Context Management: LSTM networks maintain context during the conversation, ensuring continuity and coherence.
